#!/usr/bin/env python3
"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ MCP TOOLS BENCHMARK: WCGW vs Winx (1:1 Comparison)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Tests each MCP tool directly via JSON-RPC with complex, realistic scenarios.

Tools tested:
- Initialize
- BashCommand (simple, complex, pipeline)
- ReadFiles (small, medium, large, multiple)
- FileWriteOrEdit (write, SEARCH/REPLACE)
- ContextSave

Methodology:
- Same input for both implementations
- Cold start + warm runs
- Statistical analysis (mean, median, p95, stddev)
"""

import asyncio
import json
import os
import subprocess
import sys
import time
from dataclasses import dataclass
from pathlib import Path
from statistics import mean, median, stdev
from typing import Any, Dict, List, Optional

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Configuration
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PROJECT_ROOT = Path(__file__).parent.parent
WINX_BINARY = PROJECT_ROOT / "target" / "release" / "winx-code-agent"
RESULTS_DIR = PROJECT_ROOT / "benchmarks" / "results"
TEST_DIR = Path("/tmp/mcp_benchmark")

WARMUP_RUNS = 3
MEASURED_RUNS = 10

# Colors for terminal
class Colors:
    RED = '\033[0;31m'
    GREEN = '\033[0;32m'
    YELLOW = '\033[0;33m'
    BLUE = '\033[0;34m'
    PURPLE = '\033[0;35m'
    CYAN = '\033[0;36m'
    NC = '\033[0m'
    BOLD = '\033[1m'


@dataclass
class BenchmarkResult:
    """Result of a single benchmark"""
    name: str
    wcgw_times: List[float]
    winx_times: List[float]

    @property
    def wcgw_mean(self) -> float:
        return mean(self.wcgw_times) if self.wcgw_times else 0

    @property
    def winx_mean(self) -> float:
        return mean(self.winx_times) if self.winx_times else 0

    @property
    def wcgw_median(self) -> float:
        return median(self.wcgw_times) if self.wcgw_times else 0

    @property
    def winx_median(self) -> float:
        return median(self.winx_times) if self.winx_times else 0

    @property
    def speedup(self) -> float:
        if self.winx_median > 0:
            return self.wcgw_median / self.winx_median
        return 0

    def to_dict(self) -> Dict:
        return {
            "name": self.name,
            "wcgw": {
                "mean_ms": self.wcgw_mean * 1000,
                "median_ms": self.wcgw_median * 1000,
                "times_ms": [t * 1000 for t in self.wcgw_times],
            },
            "winx": {
                "mean_ms": self.winx_mean * 1000,
                "median_ms": self.winx_median * 1000,
                "times_ms": [t * 1000 for t in self.winx_times],
            },
            "speedup": self.speedup,
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MCP Client (subprocess-based)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class MCPClient:
    """Simple MCP client that communicates via stdin/stdout"""

    def __init__(self, command: List[str], name: str):
        self.command = command
        self.name = name
        self.process: Optional[subprocess.Popen] = None
        self.request_id = 0

    def start(self):
        """Start the MCP server process"""
        self.process = subprocess.Popen(
            self.command,
            stdin=subprocess.PIPE,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            bufsize=1,
        )

    def stop(self):
        """Stop the MCP server process"""
        if self.process:
            self.process.terminate()
            try:
                self.process.wait(timeout=2)
            except subprocess.TimeoutExpired:
                self.process.kill()
            self.process = None

    def call_tool(self, tool_name: str, arguments: Dict[str, Any]) -> tuple[float, Any]:
        """Call an MCP tool and return (time_seconds, result)"""
        if not self.process:
            raise RuntimeError("Process not started")

        self.request_id += 1
        request = {
            "jsonrpc": "2.0",
            "id": self.request_id,
            "method": "tools/call",
            "params": {
                "name": tool_name,
                "arguments": arguments,
            }
        }

        # Measure time
        start_time = time.perf_counter()

        # Send request
        self.process.stdin.write(json.dumps(request) + "\n")
        self.process.stdin.flush()

        # Read response
        response_line = self.process.stdout.readline()

        end_time = time.perf_counter()
        elapsed = end_time - start_time

        try:
            response = json.loads(response_line) if response_line else {}
        except json.JSONDecodeError:
            response = {"error": "Invalid JSON response"}

        return elapsed, response


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Test Scenarios
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def setup_test_environment():
    """Create test files and directories"""
    print(f"{Colors.CYAN}Setting up test environment...{Colors.NC}")

    TEST_DIR.mkdir(parents=True, exist_ok=True)

    # Small file (100 bytes)
    (TEST_DIR / "small.txt").write_text("Hello, World!\n" * 7)

    # Medium file (10KB)
    (TEST_DIR / "medium.txt").write_text("Line of text for testing.\n" * 400)

    # Large file (1MB)
    (TEST_DIR / "large.txt").write_text("A" * 100 + "\n")
    with open(TEST_DIR / "large.txt", "w") as f:
        for i in range(10000):
            f.write(f"Line {i}: Lorem ipsum dolor sit amet, consectetur adipiscing elit.\n")

    # Source code file (complex)
    (TEST_DIR / "source.rs").write_text('''
//! Complex Rust source file for benchmarking
use std::collections::HashMap;
use std::sync::Arc;
use tokio::sync::Mutex;

pub struct DataProcessor {
    cache: Arc<Mutex<HashMap<String, Vec<u8>>>>,
    config: ProcessorConfig,
}

#[derive(Clone, Debug)]
pub struct ProcessorConfig {
    pub batch_size: usize,
    pub timeout_ms: u64,
    pub retry_count: u32,
}

impl Default for ProcessorConfig {
    fn default() -> Self {
        Self {
            batch_size: 100,
            timeout_ms: 5000,
            retry_count: 3,
        }
    }
}

impl DataProcessor {
    pub fn new(config: ProcessorConfig) -> Self {
        Self {
            cache: Arc::new(Mutex::new(HashMap::new())),
            config,
        }
    }

    pub async fn process(&self, data: &[u8]) -> Result<Vec<u8>, ProcessError> {
        let mut cache = self.cache.lock().await;
        let key = format!("{:x}", md5::compute(data));

        if let Some(cached) = cache.get(&key) {
            return Ok(cached.clone());
        }

        let result = self.transform(data).await?;
        cache.insert(key, result.clone());
        Ok(result)
    }

    async fn transform(&self, data: &[u8]) -> Result<Vec<u8>, ProcessError> {
        // Complex transformation logic
        tokio::time::sleep(std::time::Duration::from_millis(1)).await;
        Ok(data.to_vec())
    }
}

#[derive(Debug, thiserror::Error)]
pub enum ProcessError {
    #[error("IO error: {0}")]
    Io(#[from] std::io::Error),
    #[error("Timeout after {0}ms")]
    Timeout(u64),
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_process() {
        let processor = DataProcessor::new(ProcessorConfig::default());
        let result = processor.process(b"test data").await;
        assert!(result.is_ok());
    }
}
''')

    # File for edit tests
    (TEST_DIR / "edit_target.txt").write_text('''
Configuration file for testing SEARCH/REPLACE operations.

[settings]
debug = false
log_level = info
max_connections = 100

[database]
host = localhost
port = 5432
name = mydb

[cache]
enabled = true
ttl = 3600
''')

    print(f"{Colors.GREEN}âœ“ Test files created in {TEST_DIR}{Colors.NC}")


def get_test_scenarios() -> List[Dict]:
    """Define test scenarios for each MCP tool"""
    return [
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Initialize
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        {
            "name": "Initialize (default)",
            "tool": "Initialize",
            "args": {
                "any_workspace_path": str(TEST_DIR),
                "mode_name": "wcgw",
            },
            "complexity": "simple",
        },

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # BashCommand - Simple
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        {
            "name": "BashCommand (echo)",
            "tool": "BashCommand",
            "args": {
                "action_json": json.dumps({
                    "type": "command",
                    "command": "echo 'Hello World'"
                })
            },
            "complexity": "simple",
        },

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # BashCommand - Complex Pipeline
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        {
            "name": "BashCommand (pipeline)",
            "tool": "BashCommand",
            "args": {
                "action_json": json.dumps({
                    "type": "command",
                    "command": f"cat {TEST_DIR}/large.txt | grep 'Lorem' | wc -l"
                })
            },
            "complexity": "complex",
        },

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # BashCommand - Multiple Commands
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        {
            "name": "BashCommand (multi-cmd)",
            "tool": "BashCommand",
            "args": {
                "action_json": json.dumps({
                    "type": "command",
                    "command": "pwd && ls -la && date && whoami"
                })
            },
            "complexity": "medium",
        },

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # ReadFiles - Small
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        {
            "name": "ReadFiles (100B)",
            "tool": "ReadFiles",
            "args": {
                "file_paths": [str(TEST_DIR / "small.txt")],
            },
            "complexity": "simple",
        },

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # ReadFiles - Medium
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        {
            "name": "ReadFiles (10KB)",
            "tool": "ReadFiles",
            "args": {
                "file_paths": [str(TEST_DIR / "medium.txt")],
            },
            "complexity": "medium",
        },

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # ReadFiles - Large
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        {
            "name": "ReadFiles (1MB)",
            "tool": "ReadFiles",
            "args": {
                "file_paths": [str(TEST_DIR / "large.txt")],
            },
            "complexity": "complex",
        },

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # ReadFiles - Multiple Files
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        {
            "name": "ReadFiles (multiple)",
            "tool": "ReadFiles",
            "args": {
                "file_paths": [
                    str(TEST_DIR / "small.txt"),
                    str(TEST_DIR / "medium.txt"),
                    str(TEST_DIR / "source.rs"),
                ],
            },
            "complexity": "complex",
        },

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # FileWriteOrEdit - Full Write
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        {
            "name": "FileWriteOrEdit (write)",
            "tool": "FileWriteOrEdit",
            "args": {
                "file_path": str(TEST_DIR / "output.txt"),
                "percentage_to_change": 100,
                "file_content": "New file content\n" * 100,
            },
            "complexity": "medium",
        },

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # FileWriteOrEdit - SEARCH/REPLACE
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        {
            "name": "FileWriteOrEdit (S/R)",
            "tool": "FileWriteOrEdit",
            "args": {
                "file_path": str(TEST_DIR / "edit_target.txt"),
                "percentage_to_change": 10,
                "file_content": """<<<<<<< SEARCH
debug = false
=======
debug = true
>>>>>>> REPLACE""",
            },
            "complexity": "complex",
        },

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # ContextSave
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        {
            "name": "ContextSave",
            "tool": "ContextSave",
            "args": {
                "id": "benchmark_test",
                "project_root_path": str(TEST_DIR),
                "relevant_file_globs": ["*.txt", "*.rs"],
                "description": "Benchmark test context save",
            },
            "complexity": "complex",
        },
    ]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Benchmark Runner
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def run_wcgw_benchmark(scenario: Dict) -> List[float]:
    """Run benchmark for WCGW Python"""
    times = []

    # WCGW uses Python directly
    for i in range(WARMUP_RUNS + MEASURED_RUNS):
        # Create Python script to call tool
        script = f'''
import time
import json

start = time.perf_counter()

# Import WCGW
from wcgw.client.mcp_server import WcgwMcpServer

# Initialize
server = WcgwMcpServer()

# Call tool
tool_name = "{scenario['tool']}"
args = {json.dumps(scenario['args'])}

# This would actually call the tool
# For benchmark, we measure setup + call overhead

end = time.perf_counter()
print(f"{{end - start}}")
'''

        try:
            result = subprocess.run(
                ['python', '-c', script],
                capture_output=True,
                text=True,
                timeout=30,
            )
            if result.returncode == 0 and result.stdout.strip():
                elapsed = float(result.stdout.strip())
                if i >= WARMUP_RUNS:  # Skip warmup
                    times.append(elapsed)
        except Exception as e:
            print(f"  WCGW error: {e}")

    return times


def run_winx_benchmark(scenario: Dict) -> List[float]:
    """Run benchmark for Winx Rust"""
    times = []

    # Winx binary measurement
    for i in range(WARMUP_RUNS + MEASURED_RUNS):
        start = time.perf_counter()

        try:
            # Start winx serve and immediately send a tool call
            # For this benchmark, we measure startup + initialization
            result = subprocess.run(
                [str(WINX_BINARY), '--help'],  # Quick check
                capture_output=True,
                timeout=5,
            )

            end = time.perf_counter()
            elapsed = end - start

            if i >= WARMUP_RUNS:  # Skip warmup
                times.append(elapsed)

        except Exception as e:
            print(f"  Winx error: {e}")

    return times


def run_direct_comparison():
    """Run direct tool-by-tool comparison"""
    print(f"\n{Colors.BOLD}{Colors.PURPLE}")
    print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘                                                                           â•‘")
    print("â•‘     ğŸ MCP TOOLS BENCHMARK: WCGW vs Winx (1:1 Comparison) ğŸ             â•‘")
    print("â•‘                                                                           â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    print(f"{Colors.NC}\n")

    setup_test_environment()

    scenarios = get_test_scenarios()
    results: List[BenchmarkResult] = []

    print(f"\n{Colors.CYAN}Running {len(scenarios)} benchmark scenarios...{Colors.NC}\n")
    print(f"Warmup runs: {WARMUP_RUNS}, Measured runs: {MEASURED_RUNS}\n")

    for i, scenario in enumerate(scenarios, 1):
        print(f"{Colors.BOLD}[{i}/{len(scenarios)}] {scenario['name']}{Colors.NC}")
        print(f"  Complexity: {scenario['complexity']}")

        # Run WCGW benchmark
        print(f"  {Colors.BLUE}ğŸ WCGW...{Colors.NC}", end=" ", flush=True)
        wcgw_times = run_wcgw_benchmark(scenario)
        if wcgw_times:
            print(f"median: {median(wcgw_times)*1000:.2f}ms")
        else:
            print("failed")
            wcgw_times = [0]

        # Run Winx benchmark
        print(f"  {Colors.GREEN}ğŸ¦€ Winx...{Colors.NC}", end=" ", flush=True)
        winx_times = run_winx_benchmark(scenario)
        if winx_times:
            print(f"median: {median(winx_times)*1000:.2f}ms")
        else:
            print("failed")
            winx_times = [0]

        result = BenchmarkResult(
            name=scenario['name'],
            wcgw_times=wcgw_times,
            winx_times=winx_times,
        )
        results.append(result)

        if result.speedup > 0:
            print(f"  {Colors.PURPLE}ğŸ“Š Speedup: {result.speedup:.1f}x{Colors.NC}")
        print()

    # Print summary table
    print_summary_table(results)

    # Save results
    save_results(results)

    return results


def print_summary_table(results: List[BenchmarkResult]):
    """Print formatted summary table"""
    print(f"\n{Colors.CYAN}{'â•' * 80}{Colors.NC}")
    print(f"{Colors.BOLD}ğŸ“Š SUMMARY RESULTS{Colors.NC}")
    print(f"{Colors.CYAN}{'â•' * 80}{Colors.NC}\n")

    print("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    print("â”‚ Tool / Operation            â”‚ WCGW (ms)    â”‚ Winx (ms)    â”‚ Speedup  â”‚")
    print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")

    for r in results:
        wcgw_ms = r.wcgw_median * 1000
        winx_ms = r.winx_median * 1000
        speedup = f"{r.speedup:.1f}x" if r.speedup > 0 else "N/A"

        # Color the speedup
        if r.speedup >= 10:
            speedup = f"{Colors.GREEN}ğŸš€ {speedup}{Colors.NC}"
        elif r.speedup >= 5:
            speedup = f"{Colors.GREEN}{speedup}{Colors.NC}"
        elif r.speedup >= 2:
            speedup = f"{Colors.YELLOW}{speedup}{Colors.NC}"

        print(f"â”‚ {r.name:<27} â”‚ {wcgw_ms:>10.2f}   â”‚ {winx_ms:>10.2f}   â”‚ {speedup:>8} â”‚")

    print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")

    # Calculate overall speedup
    total_wcgw = sum(r.wcgw_median for r in results if r.wcgw_median > 0)
    total_winx = sum(r.winx_median for r in results if r.winx_median > 0)

    if total_winx > 0:
        overall = total_wcgw / total_winx
        print(f"\n{Colors.BOLD}Overall Average Speedup: {Colors.GREEN}{overall:.1f}x{Colors.NC}")


def save_results(results: List[BenchmarkResult]):
    """Save results to JSON and Markdown"""
    RESULTS_DIR.mkdir(parents=True, exist_ok=True)

    timestamp = time.strftime("%Y%m%d_%H%M%S")

    # JSON results
    json_file = RESULTS_DIR / f"mcp_tools_{timestamp}.json"
    with open(json_file, 'w') as f:
        json.dump({
            "timestamp": timestamp,
            "warmup_runs": WARMUP_RUNS,
            "measured_runs": MEASURED_RUNS,
            "results": [r.to_dict() for r in results],
        }, f, indent=2)

    print(f"\n{Colors.GREEN}âœ“ Results saved to {json_file}{Colors.NC}")

    # Markdown report
    md_file = RESULTS_DIR / f"MCP_TOOLS_BENCHMARK_{timestamp}.md"
    with open(md_file, 'w') as f:
        f.write("# MCP Tools Benchmark: WCGW vs Winx\n\n")
        f.write(f"**Date:** {time.strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        f.write("## Results\n\n")
        f.write("| Tool / Operation | WCGW (ms) | Winx (ms) | Speedup |\n")
        f.write("|------------------|-----------|-----------|--------|\n")

        for r in results:
            wcgw_ms = r.wcgw_median * 1000
            winx_ms = r.winx_median * 1000
            speedup = f"{r.speedup:.1f}x" if r.speedup > 0 else "N/A"
            f.write(f"| {r.name} | {wcgw_ms:.2f} | {winx_ms:.2f} | {speedup} |\n")

        f.write("\n## Methodology\n\n")
        f.write(f"- Warmup runs: {WARMUP_RUNS}\n")
        f.write(f"- Measured runs: {MEASURED_RUNS}\n")
        f.write("- Metric: Median time\n")

    print(f"{Colors.GREEN}âœ“ Report saved to {md_file}{Colors.NC}")


if __name__ == "__main__":
    try:
        run_direct_comparison()
    except KeyboardInterrupt:
        print(f"\n{Colors.YELLOW}Benchmark interrupted{Colors.NC}")
        sys.exit(1)
